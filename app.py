# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1It1URJXLvibX7afIayf6O41RzLdPMSfU
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from agent_utils import (
#     generate_sql,
#     run_sql_with_autorepair,
#     explain_results,
#     auto_plot,
# )
# 
# st.set_page_config(page_title="AI Data Analyst Agent", layout="wide")
# 
# st.title("ü§ñ AI Data Analyst Agent")
# st.caption("Text ‚Üí SQL (RAG) ‚Üí Execute ‚Üí Auto-Repair ‚Üí Explain ‚Üí Chart")
# 
# # -----------------------------
# # Session memory
# # -----------------------------
# if "memory" not in st.session_state:
#     st.session_state.memory = {
#         "last_question": None,
#         "last_sql": None
#     }
# 
# if "chat" not in st.session_state:
#     st.session_state.chat = []
# 
# def build_memory_context():
#     if st.session_state.memory["last_sql"]:
#         return f"""
# Previous Question:
# {st.session_state.memory["last_question"]}
# 
# Previous SQL:
# {st.session_state.memory["last_sql"]}
# """.strip()
#     return ""
# 
# # -----------------------------
# # Chat input
# # -----------------------------
# question = st.chat_input("Ask a question like: 'Top 5 categories by revenue'")
# 
# if question:
#     st.session_state.chat.append({"role": "user", "content": question})
# 
#     with st.spinner("Generating SQL and running it..."):
#         memory_context = build_memory_context()
#         initial_sql = generate_sql(question, memory_context=memory_context)
#         final_sql, df = run_sql_with_autorepair(question, initial_sql, max_retries=2)
# 
#         explanation = explain_results(question, final_sql, df)
#         fig = auto_plot(df, title=question)
# 
#         st.session_state.memory["last_question"] = question
#         st.session_state.memory["last_sql"] = final_sql
# 
#     st.session_state.chat.append({
#         "role": "assistant",
#         "content": explanation,
#         "sql": final_sql,
#         "df": df,
#         "has_fig": fig is not None
#     })
#     st.session_state._last_fig = fig  # store latest fig separately
# 
# # -----------------------------
# # Render chat
# # -----------------------------
# for msg in st.session_state.chat:
#     if msg["role"] == "user":
#         st.chat_message("user").write(msg["content"])
#     else:
#         st.chat_message("assistant").write(msg["content"])
# 
#         with st.expander("üîç SQL used"):
#             st.code(msg["sql"], language="sql")
# 
#         st.dataframe(msg["df"], use_container_width=True)
# 
# # Show latest chart (if exists)
# if "_last_fig" in st.session_state and st.session_state._last_fig is not None:
#     st.subheader("üìà Chart")
#     st.pyplot(st.session_state._last_fig)
# 
# # Utilities
# col1, col2 = st.columns(2)
# with col1:
#     if st.button("Clear conversation"):
#         st.session_state.chat = []
#         st.session_state.memory = {"last_question": None, "last_sql": None}
#         st.session_state._last_fig = None
# 
# with col2:
#     st.download_button(
#         "Download latest results as CSV",
#         data=(st.session_state.chat[-1]["df"].to_csv(index=False).encode("utf-8")
#               if st.session_state.chat and st.session_state.chat[-1]["role"] == "assistant"
#               else b""),
#         file_name="results.csv",
#         mime="text/csv",
#         disabled=not (st.session_state.chat and st.session_state.chat[-1]["role"] == "assistant")
#     )
#